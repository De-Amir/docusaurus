---
title: OPQ Makai
sidebar_label: Makai
---

OPQ Makai is a set of distributed services which together are responsible for aggregating and processing the measurements generated by the OPQBoxes. OPQ Makai is made up of three software components, each responsible for a specific task in the OPQ ecosystem. These components are:

* Triggering Broker.
* Acquisition Broker.
* Triggering Service.

Makai system uses [0MQ](http://zeromq.org/) for transport and [protobuf](https://developers.google.com/protocol-buffers/) for serialization. This allows easy integration with heterogeneous and polylingual systems, such as OPQ Mauka and OPQ View.The block diagram of Makai components is shown bellow:

<img src="/docs/assets/makai/makai_main.svg">

## Triggering Broker

Triggering broker is used as an endpoint for the feature reduced data generated by the OPQBox devices. Furthermore, it serves as a endpoint for the rest of the OPQ infrastructure for receiving OPQBox triggering stream. It receives frequency, Vrms and THD measurements from the OPQBox and forwards them to the connected clients. Every client is authenticated using the 0MQ security suite CurveMQ. In order to do that, a public key of every OPQBox must be provided to the TriggeringBroker at startup. Furthermore in order to authenticate the TriggeringBroker it's public key is distributed to every OPQBox. Triggeringbroker uses a SUB socket pair for receiving data from the box and a PUB socket from forwarding data further down the line. 

### Configuration
By default triggering broker will look for it's configuration file in `/etc/opq/triggering_broker.json` A default configuration file is shown below:

```
{
  "client_certs": "/etc/opq/curve/public_keys",
  "server_cert": "/etc/opq/curve/private_keys/opqserver_secret",
  "interface": "tcp://*:9880",
  "backend" : "tcp://*:9881"
}
```

Fields are as follows:
* *client_cert* : directory containing public keys of the OPQBoxes.
* *server_cert* : private key of the Triggering Broker.
* *interface* : endpoint for the OPQBox.
* *backend* : endpoint for the cloud infrastructure

### Interface

In order to communicate with the triggering broker, connect to backend port with using ZMQ SUB socket with a language of your choice and subscribe to OPQBox2 IDs you would like to receive data from. Alternatively and empty subscription will receive data from all devices. Each message contains two frames. The first frame is the box id encoded as a string. The second frame contains a protobuf encoded TriggerMessage described in the [Protocol](/docs/protocol.html) section.

## Acquisition Broker

Acquisition Broker is a microservice responsible for raw waveform acquisition from the OPQBoxes. Similarly to the triggering broker, all communication between OPQBox and acquisition broker is authenticated and encrypted using the CurveMQ. The diagram of the acquisiton broker interfaces is shown below:

<img src="/docs/assets/makai/acq_brk.png">

OPQBoxes connect to the acquisition broker's PUB interface and wait for a raw data requests. Once a raw data request arrives it is forwarded to the acquisition broker via the PULL interface. Raw waveform data as well as the event request are logged in the MongoDB. For Mongodb schema data model examine the [Data Model](/docs/datamodel.html) section.

### Configuration
By default acquisition broker will attempt to load a configuration file located in `/etc/opq/acquisition_broker_config.json`. Alternatively a configuration file can be passed as a command line argument.

```
{
  "client_certs": "/etc/opq/curve/public_keys",
  "server_cert": "/etc/opq/curve/private_keys/opqserver_secret",
  "box_pub": "tcp://*:8194",
  "box_pull": "tcp://*:8196",
  "backend_pull": "tcp://*:9884",
  "backend_pub": "tcp://*:9882",
  "mongo_uri": "mongodb://localhost:27017"
}
```

The fields are as follows:
* *client_certs* : path to directory containing OPQBox public keys.
* *server_cert* : path to the server private key.
* *box_pub* : a PUB interface for OPQBox.
* *box_pull* : a PULL interface for the OPQBox.
* *backend_pull* : an OPQHub PULL endpoint.
* *backend_pub* : an OPQHub PUB endpoint.
* *mongo_uri* : mongo host and port.

### Interface:

In oder to initiate an event acquisition a client connects to the Acquisition broker's PULL interface and send it a protobuf encoded [ReqtestDataMessage](/docs/protocol.html). Furthermore any client connected to the PUB interface will be notified of a new event by receiving a text encoded event number.

## Triggering Service

Triggering service is responsible for analyzing the triggering streams from the OPQBoxes and requesting raw waveforms whenever an anomaly is detected. Furthermore the acquisition service maintains the measurements and trends [collections](/docs/datamodel.html). Measurements are a copy of the measurement stream, maintained in the database over 24 hour interval, while trends are persistent averages of the measurements stream over a 1 minute window. The triggering service does not have any inherent logic for triggering stream analysis. Instead, it relies on analysis plugins loaded form dynamic libraries to analyse the incoming measurements and locate anomalies. This allows multiple analysis As such the Triggering service consists of three parts:
* *makai daemon* : the daemon responsible for measurements acquisition, plugin managements and communication with the acquisition service.
* *opqapi shard library* : a shared library that defines the plugin interface and communication data structures.
* *plugins* : a set of dynamic libraries which implements the plugin interface responsible for the triggering stream analysis.

### Configuring Triggering Service.
makai daemon will look for it's configuration file in `/etc/opq/makai.conf`, unless it's passed in as a command line argument. A typical configuration for the triggering service is shown bellow:

```
{
  "zmq_trigger_endpoint" : "tcp://127.0.0.1:9881",
  "zmq_acquisition_endpoint" : "tcp://127.0.0.1:9881",
  "mongo_host" : "localhost",
  "mongo_port" : 27017,
  "mongo_measurement_expiration_seconds" : 86400,
  "mongo_trends_update_interval_seconds" : 60,
  "event_request_expiration_window_ms" : 1800000,
  "plugins" : [
    {
      "path" : "/usr/local/lib/opq/plugins/libketos_plugin.so",
      "script_path" : "./main.ket"
    }
  ]
}
```
The list of fields is shown below:

* *zmq_trigger_endpoint* : triggering service endpoint.
* *zmq_acquisition_endpoint* : acquisition broker end point.
* *mongo_host* : mongo db host.
* *mongo_port* : mongo db port.
* *mongo_measurement_expiration_seconds*  : how long the measurements persist in mongo.
* *mongo_trends_update_interval_seconds* : the window width for trend averaging.
* *event_request_expiration_window_ms*	:	internal do not change.
* *plugins* : a list of plugins with object specific settings. The path field is required.

### Developing new plugins in Rust.

Triggering service is developed in [Rust](www.rust-lang.org) programing language. As such the most straight forward way to develop triggering service plugins is using the Rust programing language. An simple example of a plugin writen in Rust is found [here](https://github.com/openpowerquality/opq/blob/master/makai/TriggeringService/plugins/print/src/lib.rs). The only requirement for a plugin is a struct that implements the [MakaiPlugin](https://github.com/openpowerquality/opq/blob/master/makai/TriggeringService/opqapi/src/makaiplugin/mod.rs) traits, and that the library includes the `declare_plugin!` macro for bringing this struct across the rust FFI boundary into the daemon type system. Not that the data types `TriggerMessage` and `RequestEventMessage` are auto-generated by protobuf and their description can be found in the [protocol](/docs/protocol.html) section. 

### Developing new plugins in C/C++

Since Rust FFI is designed to interoperate with C/C++ it is quite easy to develop analysis plugins in C/C++. The only requirement is a Rust shim which implements the correct traits and defines the translation between the rust and C/C++ types.

### Developing new plugins in X language.

For a natively compiled language, as long as the language has a C/C++ binding that binding can interplay with rust. Again the only requirement is a Rust shim which translates the rust types into C/C++ types and finally into the types of a language of your choice. Many interpreted languages such as Python and JS have rust bindings for their virtual machines. An example of embedding a VM into the triggering service plugin is shown [here](https://github.com/openpowerquality/opq/blob/master/makai/TriggeringService/plugins/ketos/). Here a lisp VM is embedded into the rust plugin which provides type translation and runtime for lisp [scripts](https://github.com/openpowerquality/opq/blob/master/makai/TriggeringService/plugins/ketos/main.ket) to perform analysis and triggering. A similar plugin can be developed for any interpreted language with rust bindings.
